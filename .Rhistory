library(tidyverse)
library(googledrive)
?download.file
download.file('andlter.forestry.oregonstate.edu/ltermeta/ltersearch/dataaccess.aspx?docid=HT00441_v7.csv','temp.csv')
for(i in 1:10){
print(i)
}
lagos <- LAGOSNE::lagosne_load()
names(lagos$epi_nutr)
epi <- lagos$epi_nutr
table(epi$secchi_censorcode)
table(epi$methodinfo)
table(epi$secchi_methodinfo)
table(epi$chla_methodinfo)
2^50
2^49
table(epi$tn_censorcode)
install.packages(c("RCurl", "tidylog"))
library(RCurl)
library(tidyverse)
library(googlesheets)
library(tidylog)
#PASTA terminology:
#packageId ex: knb-lter-arc.1226.2 where arc=site, 1226=identifier, 2=revision
#each package contains 1 or more elements (e.g. datasets) with elementIds
lter_download = function(src_df, lter_dir, dmn){
#src_df must have the following columns:
#id: LTER packageId,
#domain: must match subdir name for domain in lter folder,
#pretty_name: will be printed to the user (in bookdown)
#type: dateset category, e.g. "snow depth"
#in_workflow: 0=ignored, 1=included (currently handled in global env)
#lter_dir is the local parent folder for all lter domains,
#e.g. HJ Andrews, HBEF, etc.
#dmn must match subdir name for domain in lter folder.
#this will also be used to filter src_df
`%>%` = plyr::`%>%`
endpoint = 'https://pasta.lternet.edu/package/data/eml/'
src_df = tidylog::filter(src_df, domain == dmn)
for(i in 1:nrow(src_df)){
pid = src_df$pid_str[i]
element_ids = RCurl::getURLContent(paste0(endpoint, pid))
element_ids = strsplit(element_ids, '\n')[[1]]
rawdir = paste0(dmn, '/raw/', src_df$id[i])
for(e in element_ids){
dir.create(rawdir, showWarnings=FALSE)
rawfile = paste0(rawdir, '/', e, '.csv')
download.file(url=paste0(endpoint, pid, e),
destfile=rawfile, cacheOK=FALSE, method='curl')
}
print(paste0(i, ': Downloaded ', src_df$type[i], ' (',
src_df$pretty_name[i], ') to ', lter_dir, '/', rawfile))
}
}
lterdir = '~/git/macrosheds/data_acquisition/data/lter/'
#could totally put this part inside the function too
lter_srcs = googlesheets::gs_title('lter_package_ids') %>%
googlesheets::gs_read() %>%
tidylog::filter(in_workflow == 1) %>%
tidylog::mutate(pid_str=stringr::str_replace(id, '^(.+?-.+?-.+?)\\.([0-9]+)$',
'\\1/\\2/newest/'))
lter_download(lter_srcs, lter_dir=lterdir, dmn='south_umpqua')
lter_download(lter_srcs, lter_dir=lterdir, dmn='south_umpqua')
lter_download = function(src_df, lter_dir, dmn){
#src_df must have the following columns:
#id: LTER packageId,
#domain: must match subdir name for domain in lter folder,
#pretty_name: will be printed to the user (in bookdown)
#type: dateset category, e.g. "snow depth"
#in_workflow: 0=ignored, 1=included (currently handled in global env)
#lter_dir is the local parent folder for all lter domains,
#e.g. HJ Andrews, HBEF, etc.
#dmn must match subdir name for domain in lter folder.
#this will also be used to filter src_df
`%>%` = magrittr::`%>%`
endpoint = 'https://pasta.lternet.edu/package/data/eml/'
src_df = tidylog::filter(src_df, domain == dmn)
for(i in 1:nrow(src_df)){
pid = src_df$pid_str[i]
element_ids = RCurl::getURLContent(paste0(endpoint, pid))
element_ids = strsplit(element_ids, '\n')[[1]]
rawdir = paste0(dmn, '/raw/', src_df$id[i])
for(e in element_ids){
dir.create(rawdir, showWarnings=FALSE)
rawfile = paste0(rawdir, '/', e, '.csv')
download.file(url=paste0(endpoint, pid, e),
destfile=rawfile, cacheOK=FALSE, method='curl')
}
print(paste0(i, ': Downloaded ', src_df$type[i], ' (',
src_df$pretty_name[i], ') to ', lter_dir, '/', rawfile))
}
}
lter_download(lter_srcs, lter_dir=lterdir, dmn='south_umpqua')
traceback()
library(RCurl)
lter_download(lter_srcs, lter_dir=lterdir, dmn='south_umpqua')
lter_download(lter_srcs, lter_dir=lterdir, dmn='south_umpqua')
lter_download = function(src_df, lter_dir, dmn){
#src_df must have the following columns:
#id: LTER packageId,
#domain: must match subdir name for domain in lter folder,
#pretty_name: will be printed to the user (in bookdown)
#type: dateset category, e.g. "snow depth"
#in_workflow: 0=ignored, 1=included (currently handled in global env)
#lter_dir is the local parent folder for all lter domains,
#e.g. HJ Andrews, HBEF, etc.
#dmn must match subdir name for domain in lter folder.
#this will also be used to filter src_df
`%>%` = magrittr::`%>%`
endpoint = 'https://pasta.lternet.edu/package/data/eml/'
src_df = tidylog::filter(src_df, domain == dmn)
for(i in 1:nrow(src_df)){
pid = src_df$pid_str[i]
element_ids = RCurl::getURLContent(paste0(endpoint, pid))
element_ids = strsplit(element_ids, '\n')[[1]]
rawdir = paste0(dmn, '/raw/', src_df$id[i])
for(e in element_ids){
dir.create(rawdir, showWarnings=FALSE)
rawfile = paste0(rawdir, '/', e, '.csv')
download.file(url=paste0(endpoint, pid, e),
destfile=rawfile, cacheOK=FALSE, method='auto')
}
print(paste0(i, ': Downloaded ', src_df$type[i], ' (',
src_df$pretty_name[i], ') to ', lter_dir, '/', rawfile))
}
}
lter_download = function(src_df, lter_dir, dmn){
#src_df must have the following columns:
#id: LTER packageId,
#domain: must match subdir name for domain in lter folder,
#pretty_name: will be printed to the user (in bookdown)
#type: dateset category, e.g. "snow depth"
#in_workflow: 0=ignored, 1=included (currently handled in global env)
#lter_dir is the local parent folder for all lter domains,
#e.g. HJ Andrews, HBEF, etc.
#dmn must match subdir name for domain in lter folder.
#this will also be used to filter src_df
`%>%` = magrittr::`%>%`
endpoint = 'https://pasta.lternet.edu/package/data/eml/'
src_df = tidylog::filter(src_df, domain == dmn)
for(i in 1:nrow(src_df)){
pid = src_df$pid_str[i]
element_ids = RCurl::getURLContent(paste0(endpoint, pid))
element_ids = strsplit(element_ids, '\n')[[1]]
rawdir = paste0(dmn, '/raw/', src_df$id[i])
for(e in element_ids){
dir.create(rawdir, showWarnings=FALSE)
rawfile = paste0(rawdir, '/', e, '.csv')
download.file(url=paste0(endpoint, pid, e),
destfile=rawfile, cacheOK=FALSE, method='auto')
}
print(paste0(i, ': Downloaded ', src_df$type[i], ' (',
src_df$pretty_name[i], ') to ', lter_dir, '/', rawfile))
}
}
lterdir = '~/git/macrosheds/data_acquisition/data/lter/'
#could totally put this part inside the function too
lter_srcs = googlesheets::gs_title('lter_package_ids') %>%
googlesheets::gs_read() %>%
tidylog::filter(in_workflow == 1) %>%
tidylog::mutate(pid_str=stringr::str_replace(id, '^(.+?-.+?-.+?)\\.([0-9]+)$',
'\\1/\\2/newest/'))
lter_download(lter_srcs, lter_dir=lterdir, dmn='south_umpqua')
lter_dir=lterdir
src_df=lter_srcs
`%>%` = magrittr::`%>%`
endpoint = 'https://pasta.lternet.edu/package/data/eml/'
src_df = tidylog::filter(src_df, domain == dmn)
dmn='south_umpqua'
lter_download(lter_srcs, lter_dir=lterdir, dmn='hjandrews')
endpoint = 'https://pasta.lternet.edu/package/data/eml/'
src_df = tidylog::filter(src_df, domain == dmn)
lter_download(lter_srcs, lter_dir=lterdir, dmn='hjandrews')
for(i in 1:nrow(src_df)){
pid = src_df$pid_str[i]
element_ids = RCurl::getURLContent(paste0(endpoint, pid))
element_ids = strsplit(element_ids, '\n')[[1]]
rawdir = paste0(dmn, '/raw/', src_df$id[i])
for(e in element_ids){
dir.create(rawdir, showWarnings=FALSE)
rawfile = paste0(rawdir, '/', e, '.csv')
download.file(url=paste0(endpoint, pid, e),
destfile=rawfile, cacheOK=FALSE, method='curl')
}
print(paste0(i, ': Downloaded ', src_df$type[i], ' (',
src_df$pretty_name[i], ') to ', lter_dir, '/', rawfile))
}
lter_download = function(src_df, lter_dir, dmn){
#src_df must have the following columns:
#id: LTER packageId,
#domain: must match subdir name for domain in lter folder,
#pretty_name: will be printed to the user (in bookdown)
#type: dateset category, e.g. "snow depth"
#in_workflow: 0=ignored, 1=included (currently handled in global env)
#lter_dir is the local parent folder for all lter domains,
#e.g. HJ Andrews, HBEF, etc.
#dmn must match subdir name for domain in lter folder.
#this will also be used to filter src_df
`%>%` = magrittr::`%>%`
endpoint = 'https://pasta.lternet.edu/package/data/eml/'
src_df = tidylog::filter(src_df, domain == dmn)
for(i in 1:nrow(src_df)){
pid = src_df$pid_str[i]
element_ids = RCurl::getURLContent(paste0(endpoint, pid))
element_ids = strsplit(element_ids, '\n')[[1]]
rawdir = paste0(dmn, '/raw/', src_df$id[i])
for(e in element_ids){
dir.create(rawdir, showWarnings=FALSE)
rawfile = paste0(rawdir, '/', e, '.csv')
download.file(url=paste0(endpoint, pid, e),
destfile=rawfile, cacheOK=FALSE, method='curl')
}
print(paste0(i, ': Downloaded ', src_df$type[i], ' (',
src_df$pretty_name[i], ') to ', lter_dir, '/', rawfile))
}
}
lterdir = '~/git/macrosheds/data_acquisition/data/lter/'
#could totally put this part inside the function too
lter_srcs = googlesheets::gs_title('lter_package_ids') %>%
googlesheets::gs_read() %>%
tidylog::filter(in_workflow == 1) %>%
tidylog::mutate(pid_str=stringr::str_replace(id, '^(.+?-.+?-.+?)\\.([0-9]+)$',
'\\1/\\2/newest/'))
lter_download(lter_srcs, lter_dir=lterdir, dmn='hjandrews')
lter_srcs
lter_dir
lter_download(lter_srcs, lter_dir=lterdir, dmn='hjandrews')
endpoint = 'https://pasta.lternet.edu/package/data/eml/'
src_df = tidylog::filter(src_df, domain == dmn)
i=1
pid = src_df$pid_str[i]
element_ids = RCurl::getURLContent(paste0(endpoint, pid))
element_ids = strsplit(element_ids, '\n')[[1]]
rawdir = paste0(dmn, '/raw/', src_df$id[i])
dir.create(rawdir, showWarnings=FALSE)
rawdir
dir.create(rawdir, showWarnings=FALSE)
?dir.create
dir.exists(rawdir)
paste0(endpoint, pid, e)
download.file(url=paste0(endpoint, pid, e),
destfile=rawfile, cacheOK=FALSE, method='curl')
?dir.create
lter_dir
lterdir = '/data/lter/'
rawdir = paste0(lterdir,dmn, '/raw/', src_df$id[i])
rawdir
lterdir = 'data/lter/'
rawdir
rawdir = paste0(lterdir,dmn, '/raw/', src_df$id[i])
rawdir
dir.create(rawdir, showWarnings=FALSE)
?dir.create
dir.exists(rawdir)
dir.create(rawdir)
getwd()
list.files()
rawdir
rawdir
dir.create(rawdir, showWarnings=FALSE,recursive = T)
lter_download = function(src_df, lter_dir, dmn){
#src_df must have the following columns:
#id: LTER packageId,
#domain: must match subdir name for domain in lter folder,
#pretty_name: will be printed to the user (in bookdown)
#type: dateset category, e.g. "snow depth"
#in_workflow: 0=ignored, 1=included (currently handled in global env)
#lter_dir is the local parent folder for all lter domains,
#e.g. HJ Andrews, HBEF, etc.
#dmn must match subdir name for domain in lter folder.
#this will also be used to filter src_df
`%>%` = magrittr::`%>%`
endpoint = 'https://pasta.lternet.edu/package/data/eml/'
src_df = tidylog::filter(src_df, domain == dmn)
for(i in 1:nrow(src_df)){
pid = src_df$pid_str[i]
element_ids = RCurl::getURLContent(paste0(endpoint, pid))
element_ids = strsplit(element_ids, '\n')[[1]]
rawdir = paste0(lter_dir,dmn, '/raw/', src_df$id[i])
for(e in element_ids){
dir.create(rawdir, showWarnings=FALSE, recursive = TRUE)
rawfile = paste0(rawdir, '/', e, '.csv')
download.file(url=paste0(endpoint, pid, e),
destfile=rawfile, cacheOK=FALSE, method='curl')
}
print(paste0(i, ': Downloaded ', src_df$type[i], ' (',
src_df$pretty_name[i], ') to ', lter_dir, '/', rawfile))
}
}
source('src/retrieval/retrieve_lter.R')
source('src/retrieval/retrieve_lter.R')
library(tidyverse)
library(googledrive)
library(feather)
library(tidyverse)
library(googledrive)
library(feather)
library(googlesheets)
#
knitr::opts_knit$set(root.dir='../../..')
source('src/retrieval/retrieve_lter.R')
lterdir = 'data/lter/'
#could totally put this part inside the function too
lter_srcs = googlesheets::gs_title('lter_package_ids') %>%
googlesheets::gs_read() %>%
tidylog::filter(in_workflow == 1) %>%
tidylog::mutate(pid_str=stringr::str_replace(id, '^(.+?-.+?-.+?)\\.([0-9]+)$',
'\\1/\\2/newest/'))
lter_download(lter_srcs, lter_dir=lterdir, dmn='hjandrews')
src_df = lter_srcs
lter_dir=lterdir
dmn='hjandrews'
`%>%` = magrittr::`%>%`
endpoint = 'https://pasta.lternet.edu/package/data/eml/'
src_df = tidylog::filter(src_df, domain == dmn)
pid = src_df$pid_str[i]
element_ids = RCurl::getURLContent(paste0(endpoint, pid))
element_ids = strsplit(element_ids, '\n')[[1]]
i=1
pid = src_df$pid_str[i]
element_ids = RCurl::getURLContent(paste0(endpoint, pid))
element_ids = strsplit(element_ids, '\n')[[1]]
rawdir = paste0(lter_dir,dmn, '/raw/',src_df$type[i],src_df$id[i])
rawdir = paste(lter_dir,dmn, 'raw',src_df$type[i],
src_df$id[i],sep='/')
#could totally put this part inside the function too
lter_srcs = googlesheets::gs_title('lter_package_ids') %>%
googlesheets::gs_read() %>%
tidylog::filter(in_workflow == 1) %>%
tidylog::mutate(pid_str=stringr::str_replace(id, '^(.+?-.+?-.+?)\\.([0-9]+)$',
'\\1/\\2/newest/'))
rawdir = paste(lter_dir,dmn, 'raw',src_df$type[i],
src_df$id[i],sep='/')
src_df = lter_srcs
rawdir = paste(lter_dir,dmn, 'raw',src_df$type[i],
src_df$id[i],sep='/')
rawdir = paste(lter_dir,dmn, 'raw',src_df$type[i],sep='/')
rawdir = paste(lter_dir,dmn, '/raw/',src_df$type[i])
rawdir = paste0(lter_dir,dmn, '/raw/',src_df$type[i])
#library(RCurl)
#library(tidyverse)
#library(tidylog)
#PASTA terminology:
#packageId ex: knb-lter-arc.1226.2 where arc=site, 1226=identifier, 2=revision
#each package contains 1 or more elements (e.g. datasets) with elementIds
lter_download = function(src_df, lter_dir, dmn){
#src_df must have the following columns:
#id: LTER packageId,
#domain: must match subdir name for domain in lter folder,
#pretty_name: will be printed to the user (in bookdown)
#type: dateset category, e.g. "snow depth"
#in_workflow: 0=ignored, 1=included (currently handled in global env)
#lter_dir is the local parent folder for all lter domains,
#e.g. HJ Andrews, HBEF, etc.
#dmn must match subdir name for domain in lter folder.
#this will also be used to filter src_df
`%>%` = magrittr::`%>%`
endpoint = 'https://pasta.lternet.edu/package/data/eml/'
src_df = tidylog::filter(src_df, domain == dmn)
for(i in 1:nrow(src_df)){
pid = src_df$pid_str[i]
element_ids = RCurl::getURLContent(paste0(endpoint, pid))
element_ids = strsplit(element_ids, '\n')[[1]]
rawdir = paste0(lter_dir,dmn, '/raw/',src_df$type[i])
for(e in element_ids){
dir.create(rawdir, showWarnings=FALSE, recursive = TRUE)
rawfile = paste0(rawdir, '/', e, '.csv')
download.file(url=paste0(endpoint, pid, e),
destfile=rawfile, cacheOK=FALSE, method='curl')
}
print(paste0(i, ': Downloaded ', src_df$type[i], ' (',
src_df$pretty_name[i], ') to ', lter_dir, '/', rawfile))
}
}
#library(RCurl)
#library(tidyverse)
#library(tidylog)
#PASTA terminology:
#packageId ex: knb-lter-arc.1226.2 where arc=site, 1226=identifier, 2=revision
#each package contains 1 or more elements (e.g. datasets) with elementIds
lter_download = function(src_df, lter_dir, dmn){
#src_df must have the following columns:
#id: LTER packageId,
#domain: must match subdir name for domain in lter folder,
#pretty_name: will be printed to the user (in bookdown)
#type: dateset category, e.g. "snow depth"
#in_workflow: 0=ignored, 1=included (currently handled in global env)
#lter_dir is the local parent folder for all lter domains,
#e.g. HJ Andrews, HBEF, etc.
#dmn must match subdir name for domain in lter folder.
#this will also be used to filter src_df
`%>%` = magrittr::`%>%`
endpoint = 'https://pasta.lternet.edu/package/data/eml/'
src_df = tidylog::filter(src_df, domain == dmn)
for(i in 1:nrow(src_df)){
pid = src_df$pid_str[i]
element_ids = RCurl::getURLContent(paste0(endpoint, pid))
element_ids = strsplit(element_ids, '\n')[[1]]
rawdir = paste0(lter_dir,dmn, '/raw/',src_df$type[i])
for(e in element_ids){
dir.create(rawdir, showWarnings=FALSE, recursive = TRUE)
rawfile = paste0(rawdir, '/', e, '.csv')
download.file(url=paste0(endpoint, pid, e),
destfile=rawfile, cacheOK=FALSE, method='curl')
}
print(paste0(i, ': Downloaded ', src_df$type[i], ' (',
src_df$pretty_name[i], ') to ', lter_dir, '/', rawfile))
}
}
lter_download(src_df = lter_srcs, lter_dir=lterdir, dmn='hjandrews')
bookdown::render_book()
bookdown::render_book('index.Rmd')
bookdown::render_book('index.Rmd')
bookdown::render_book('index.Rmd')
bookdown::render_book('index.Rmd')
bookdown::render_book('index.Rmd')
bookdown::render_book('index.Rmd')
bookdown::render_book('index.Rmd')
bookdown::render_book('index.Rmd')
bookdown::render_book('index.Rmd')
getwd()\
getwd()
